{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tflearn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nfrom random import shuffle\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n# This Python 3 environment comes with many helpful analytiimport tflearn\nimport tflearn\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import highway_conv_2d, max_pool_2d\nfrom tflearn.layers.normalization import local_response_normalization, batch_normalization\nfrom tflearn.layers.estimator import regression\nfrom sklearn.model_selection import train_test_split\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.framework import ops\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \nfrom keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\nimport pandas as pd\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nimport skimage\nfrom skimage import io","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/nn23-sports-image-classification/Train'\npath_directory_list = os.listdir(path)\nlables=[]\nimages=[]\nimage_path=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dir in path_directory_list:\n        part = dir.split('_')[0]\n        lables.append(part)\n        image_path.append(path+'/'+dir)\n    \n   \n   \n   \n       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame()\ndf['image']=image_path\ndf['Lable']=lables\ndf['Lable'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df['Lable'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_1,class_2,class_3,class_4,class_5,class_6 = df['Lable'].value_counts()\nc1 = df[df['Lable'] == 'Yoga']\nc2 = df[df['Lable'] == 'Football']\nc3 = df[df['Lable'] == 'Swimming']\nc4 = df[df['Lable'] == 'Tennis']\nc5 = df[df['Lable'] == 'Rowing']\nc6 = df[df['Lable'] == 'Basketball']\n\ndf_1 = c2.sample(class_1, replace=True)\ndf_2 = c3.sample(class_1, replace=True)\ndf_3 = c4.sample(class_1, replace=True)\ndf_4 = c5.sample(class_1, replace=True)\ndf_5 = c6.sample(class_1, replace=True)\n\noversampled_df = pd.concat([c1,df_1,df_2,df_3,df_4,df_5], axis=0)\noversampled_df = oversampled_df.sort_index(ascending=True)\noversampled_df=oversampled_df.reset_index(drop=True)\noversampled_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(oversampled_df['Lable'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversampled_df['Lable'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel = np.array([[0, -1, 0],\n                   [-1, 5,-1],\n                   [0, -1, 0]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lables.clear()\nfor i in range(len(oversampled_df)):\n        lables.append(oversampled_df['Lable'][i])\n        img_data = cv2.imread(str(oversampled_df['image'][i]))\n        img_data = cv2.resize(img_data, (128, 128))\n        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n        #img_data = skimage.color.rgb2gray(img_data)\n        img_data = cv2.filter2D(src=img_data, ddepth=-1, kernel=kernel)\n        img_data = cv2.fastNlMeansDenoising(img_data, None, 20, 7, 21) \n        images.append(np.array(img_data))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(images[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lables=np.array(lables)\nlables=lables.reshape(-1,1)\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(lables)\ny = y.toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.array(images)\nX=(X - np.min(X)) / (np.max(X) - np.min(X))\n#X=X.reshape(-1,128,128,1)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data augmantation**","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.2 ,random_state=700, shuffle=True)\ngenerator= ImageDataGenerator(\n        featurewise_center =True,\n        featurewise_std_normalization = True,\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ngenerator.fit(x_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modeling**","metadata":{}},{"cell_type":"code","source":"#optimizer and learning rate\nopt = Adam(lr=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn4 = Sequential()\ncnn4.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(128,128,3)))\ncnn4.add(MaxPool2D())\n\ncnn4.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\ncnn4.add(MaxPool2D())\n\ncnn4.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\ncnn4.add(MaxPool2D())\n\n\ncnn4.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\ncnn4.add(MaxPool2D())\n\n\n\ncnn4.add(Dropout(0.4))\n\n\n\ncnn4.add(Flatten())\ncnn4.add(Dense(128,activation=\"relu\"))\ncnn4.add(Dense(6, activation=\"softmax\"))\n\ncnn4.summary()\ncnn4.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn4.fit(\n  x_train,\n  y_train,\n  epochs=250,\n  validation_data=(x_test,y_test),\n   batch_size=96\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential(name='VGG')\nmodel.add(Conv2D(input_shape=(128,128,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=6, activation=\"softmax\"))\nmodel.summary()\nmodel.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n  x_train,\n  y_train,\n  epochs=50,\n  validation_data=(x_test,y_test),\n  batch_size=96\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network = input_data(shape=[None, 128, 128, 3], name='input')\n\n#highway convolutions with pooling and dropout\n\nnetwork = highway_conv_2d(network, 16, 5, activation='relu')\nnetwork = highway_conv_2d(network, 16, 5, activation='relu')\nnetwork = highway_conv_2d(network, 16, 5, activation='relu')\nnetwork = max_pool_2d(network, 5)\nnetwork = batch_normalization(network)\nnetwork = fully_connected(network, 128, activation='relu')\nnetwork = fully_connected(network, 256, activation='relu')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 6, activation='softmax')\nnetwork = regression(network, optimizer='adam', learning_rate=0.0001,loss='categorical_crossentropy', name='target')\n\n# Training\nmodel2 = tflearn.DNN(network, tensorboard_dir='log', tensorboard_verbose=3)\nmodel2.fit(x_train, y_train, n_epoch=100, validation_set=(x_test, y_test),show_metric=True,batch_size=96,run_id='convnet_highway_mnist')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ops.reset_default_graph()\nconv_input = input_data(shape=[None, 128, 128,3], name='input')\nconv1 = conv_2d(conv_input, 32, 3, activation='relu')\npool1 = max_pool_2d(conv1, 3)\n\nconv2 = conv_2d(pool1, 64, 3, activation='relu')\npool2 = max_pool_2d(conv2, 3)\n\nfully_layer = fully_connected(pool2, 1024, activation='relu')\nfully_layer = dropout(fully_layer, 0.5)\n\ncnn_layers = fully_connected(fully_layer, 6, activation='softmax')\n\ncnn_layers = regression(cnn_layers, optimizer='adam', learning_rate=0.0001, loss='categorical_crossentropy', name='targets')\nmodel3 = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3.fit({'input': x_train}, {'targets': y_train}, n_epoch=50,\n          validation_set=({'input': x_test}, {'targets': y_test}),\n          snapshot_step=500, show_metric=True,batch_size=96, run_id='CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"network = input_data(shape=[None, 128, 128, 3] , name='input')\nnetwork = conv_2d(network, 32, 3, activation='relu')\nnetwork = max_pool_2d(network, 3)\nnetwork = conv_2d(network, 64, 3, activation='relu')\nnetwork = conv_2d(network, 64, 3, activation='relu')\nnetwork = max_pool_2d(network, 3)\nnetwork = fully_connected(network, 512, activation='relu')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 6, activation='softmax')\nnetwork = regression(network, optimizer='adam',loss='categorical_crossentropy',learning_rate=0.0001)\n\n# Train using classifier\nmodel4 = tflearn.DNN(network, tensorboard_verbose=0)\nmodel4.fit(x_train, y_train, n_epoch=200, shuffle=True, validation_set=(x_test, y_test),\n          show_metric=True, batch_size=96, run_id='cifar10_cnn')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path='/kaggle/input/nn23-sports-image-classification/Test'\ntest_path_directory_list = os.listdir(test_path)\ntest_images=[]\ntest_images_path=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dir in test_path_directory_list:\n        img_data = cv2.imread(test_path+'/'+dir)\n        img_data = cv2.resize(img_data, (128, 128))\n        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n        #img_data = skimage.color.rgb2gray(img_data)\n        img_data = cv2.filter2D(src=img_data, ddepth=-1, kernel=kernel)\n        img_data = cv2.fastNlMeansDenoising(img_data, None, 20, 7, 21) \n        test_images.append(np.array(img_data))\n        test_images_path.append(dir)\n \n       \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images=np.array(test_images)\ntest_images=(test_images - np.min(test_images)) / (np.max(test_images) - np.min(test_images))\n#test_images=test_images.reshape(-1,128,128,1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.core.display import HTML\nimport pandas as pd\n\ndef predections_csv(predictions):\n    finalPrediction = []\n    for i in predictions:\n    \n        finalPrediction.append(pd.Series(i).idxmax())\n        \n  \n   \n    data = {'image_name':test_images_path , 'label':finalPrediction}\n    df = pd.DataFrame(data)\n    df.to_csv('df.csv',index=False)\n    html = '<a href=df.csv>Download csv</a>'\n    html = html.format(title='Download csv',filename='df.csv')\n    return HTML(html)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=model3.predict(test_images)\npredections_csv(predictions)            \n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=model.predict(test_images)\npredections_csv(predictions)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}